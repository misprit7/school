\documentclass[letterpaper, reqno,11pt]{article}
\usepackage[margin=1.0in]{geometry}
\usepackage{color,latexsym,amsmath,amssymb,graphicx,float,listings,tikz}
\usepackage{hyperref}

\hypersetup{
colorlinks=true,
linkcolor=magenta,
filecolor=magenta,
urlcolor=cyan,
}

\graphicspath{ {images/} }

\begin{document}
\pagenumbering{arabic}
\title{Math 320 Homework 4}
\date{04/10/23}
\author{Xander Naumenko}
\maketitle

{\medskip\noindent\bf Question 1i.} False, let $x_n=n+(-1)^{n}$. Then clearly $x_n\to\infty$ (for any $M$ choose $N=M+1$, then for $n>N$ we have $x_n>n-1=M$). However for any $n$ that is even we have $x_n=n+1>n=x_{n+1}$.

{\medskip\noindent\bf Question 1ii.} The statement is true. By contradiction assume $x_n\to \infty$ with no increasing subsequence. Since no increasing subsequence exists, every increasing subset of $x_n$ is of finite length, and choose $n_1,n_2,\ldots,n_K$ be a longest such increasing subsequence. Let $N=x_{n_K}$, then since $x_n\to\infty$ there exists $N$ such that $(n>N)\implies\left( x_n>x_{n_K} \right) $. Then let $n_{K+1}=\max(n_K,N)+1$. Then $x_{n_{K+1}}>x_{n_K}$ with $n_{K+1}>n_K$, but this contradicts our assumption that the $n_1,\ldots,n_K$ were chosen to be maximal since adding $x_{n_{K+1}}$ would make a longer increasing subsequence. Thus an increasing subsequence of infinite length must exist.

\newpage\phantom{blabla}
\newpage

{\medskip\noindent\bf Question 2a.} The sequence converges. Note that we have:
\[
a_{n}=n \frac{1+\frac{1}{n}-1}{\sqrt{1+\frac{1}{n}}+1}=\frac{1}{\sqrt{1+\frac{1}{n}}+1}
.\]
I claim that $a_n\to \frac{1}{2}$. To see this let $\epsilon>0$, and choose $N=\max\left(10,\frac{1}{\left( \frac{1}{\epsilon+1 /2}-1 \right) ^2-1}\right)$. Then for $n>N$,
\[
|a_n-\frac{1}{2}|=\left| \frac{1}{\sqrt{1+\frac{1}{n}}+1} -\frac{1}{2}\right|<\epsilon
.\]

{\medskip\noindent\bf Question 2b.} The sequence does not converge. Let $L\in \mathbb{R},\epsilon=\frac{1}{2}$, and $N>0$. Choose $n$ to be an arbitrary even integer greater than $N$ if $L<0$ and an odd integer greater than $\max(N, 3)$ otherwise. Then:
\[
\left| b_n-L \right| =\left| \frac{(-1)^{n}n}{n+1}-L \right|=\left| \frac{n}{n+1} \right| +|L|> \frac{1}{2}+|L|\geq \frac{1}{2}=\epsilon
.\]

\newpage\phantom{blabla}
\newpage

{\medskip\noindent\bf Question 3a.} I claim that $\Sigma(A)$ being defined and finite implies that there is a maximum element of $A$. To see why suppose not, i.e. suppose that $\forall a\in A, \exists b\in A$ s.t. $b>a$. Then let $F\subset A$ be a subset with $\Sigma(F)\geq \Sigma(A) /2$, by hypothesis there exists $b\in A$ s.t. $b>\max(F)$. However then $\Sigma(F\cup \{b\})> \Sigma(A) /2+x\Sigma(A) /2=\Sigma(A)$, which contradicts the definition of $\Sigma$. Thus $A$ has a maximum element.

However this implies that $A$ is countable. To see why, consider letting $x_1=\max(A)$ and $A'=A\setminus \{x_1\}$. Note that since $\Sigma(A')$ is also well defined since we just removed a single element, so it also has a maximum. Then we can let $x_2=\max(A\setminus x_1)$ and so forth to enumerate all the (potentially infinite) elements of $A$. Since we've just created an onto map from $\mathbb{N}\to A$ either $A$ is countable or finite.

{\medskip\noindent\bf Question 3b.} Let $L=\lim_{n\to\infty}\sum_{n=1}^{N}a_n$. For any $F\subset  A$, clearly we have that
\[
L=\lim_{N\to\infty}\sum_{n=1}^{N}a_n\geq \sum_{f\in F}f
,\]
implying that $\Sigma(A)\leq L$. Let $R<L$, and let $\epsilon=L-R$. Then there exists $N\in \mathbb{N}$ s.t. $\forall n>N,$
\[
\left| \sum_{i=1}^{n}a_i-L \right|<\epsilon
.\]
Let $F'=\{a_n: n\leq N+1\}$. Then $\Sigma(F')=\sum_{n=1}^{N+1}a_n>L-\epsilon=R$. Since this is true independent of our choice of $R$, it must be that $\Sigma(A)=L$.

\newpage\phantom{blabla}
\newpage

{\medskip\noindent\bf Question 4a.} Let $(x,y)\in \mathbb{R}^2$. By their definition note that $W_2(y)\leq f(x,y)$ and $M_1(x)\geq f(x,y)$, since $(x,y)$ is contained in both sets that $M_1$ and $W_2$ are taking the supremum and infimum respectively. Putting those two statements together we that $\forall (x,y)\in \mathbb{R}^2, W_2(y)\leq M_1(x)$. Since this holds over all of $R^{2}$ taking the supremum and infimum over the left and right sides respectively does nothing to change this inequality, so arrive as required to
\[
\sup \{W_2(y): y\in Y\}\leq \inf \{M_1(x): x\in X\}
.\]

{\medskip\noindent\bf Question 4b.} Define
\[
f(x,y)=\begin{cases}
    1&\text{ if } x=y\\
    0&\text{ otherwise}
\end{cases}
.\]
Then we have that
\[
\sup \{W_2(y): y\in Y\}=\sup \{0\}= 0\leq 1= \inf \{1\}=\inf \{M_1(x): x\in X\}
.\]

\newpage\phantom{blabla}
\newpage

{\medskip\noindent\bf Question 5.} Let $x\in [0,\inf(S))$. Then $\forall s\in S$ we have $x<s$, so $x\in [0,s)$. Thus $x\in \bigcap_{S\in S}[0,s)$. Next let $y\in (\inf(S), \infty)$. Since $y>\inf(S)$, there exists $s\in S$ with $s<y$, so $y\notin [0,s)\implies y\notin \bigcap_{S\in S}[0,s)$. These facts about $x$ and $y$ together imply that $\bigcap_{s\in S}[0,s)=[0,\inf(S)$ or $[0,\inf(S)]$.

There are two cases: $\inf(S)\in S$ or $\inf(S)\notin S$. If it's the former, then $\inf(S)\notin [0,\inf(S))\implies \bigcap_{S\in S}[0,s)=[0,\inf(S))$. If $\inf(S)\notin S$ then $\forall s\in S, \inf(S)\in [0,s)$, so $\bigcap_{S\in S}[0,s)=[0,\inf(S)]$.

\newpage\phantom{blabla}
\newpage

{\medskip\noindent\bf Question 6a.} Let $\epsilon>0$, since $x_n$ and $y_n$ are Cauchy there exists $N_x,N_y$ s.t. $\forall n>N_x, p>0, |x_{n+p}-x_n|< \frac{\epsilon}{2}$ and $\forall n>N_y, p>0, |y_{n+p}-y_n|< \frac{\epsilon}{2}$. Let $N=\max(N_x,N_y)$. Then $\forall n>N, p>0$, we have
\[
\left| x_{n+p}+y_{n+p}-x_n-x_p \right|\leq \left| x_{n+p}-x_n \right| +\left| y_{n+p}-y_n \right| <\frac{\epsilon}{2}+\frac{\epsilon}{2}=\epsilon
.\]
Thus $x_n+y_n$ is also Cauchy.

{\medskip\noindent\bf Question 6b.} Since $x_n$ and $y_n$ are Cauchy then they are bounded, let $X,Y$ be such that $x_n>X,y_n>Y\forall n$. Define $\epsilon,N_x,N_y$ the same as for the previous part, except for $|x_{n+p}-x_n|<\frac{\epsilon}{2M}$ and $|y_{n+p}-y_n|<\frac{\epsilon}{2N}$. Then for $n>\max(N_x,N_y),p>0$, we have
\[
\left| x_{n+p}y_{n+p}-x_ny_n \right| \leq \left| x_{n+p}(y_{n+p}-y_n) \right| +\left| y_n\left( x_{n+p}-x_n \right)  \right| < \frac{\epsilon}{2}+\frac{\epsilon}{2}=\epsilon
.\]

{\medskip\noindent\bf Question 6c.} Let $\epsilon>0$, since $x_n$ is Cauchy there exists $N_x$ such that for any $n>N_x, p>0, |x_{n+p}-x_n|<\frac{\epsilon}{2}$. Also since $(y_n-x_n)\to 0$, $\exists N$ s.t. $\forall n>N,p>0,|x_{n+p}-y_{n+p}-x_{n}+y_{n}|<\frac{\epsilon}{2}$. Choose $N_y=$ and let $p>0$. Then we have that
\[
\left| y_{n+p}-y_n \right| \leq |x_{n+p}-y_{n+p}-x_{n}+y_{n}| + \left| x_{n+p}-x_{n} \right|<\frac{\epsilon}{2}+\frac{\epsilon}{2}=\epsilon
.\]

\newpage\phantom{blabla}
\newpage

{\medskip\noindent\bf Question 7a and b.} I will prove both a and b at once despite the suggestion. We will first solve the recurrence relation. Assume a solution is of the form $a^{n}=x^{n}$ for some $x\in \mathbb{R}$. For this to be true, we'd need
\[
x^{n}=(1-\lambda) x^{n-1}+\lambda x^{n-2}\implies x^2-(1-\lambda) x-\lambda=0\implies x=\frac{1}{2}\left( 1-\lambda\pm \sqrt{(1-\lambda)^2+4\lambda} \right)
\]
\[
\implies x=\frac{1}{2}\left( 1-\lambda\pm \lambda+1 \right) =-\lambda\text{ or }1
.\]
Since this is a second order recurrence relation, all solutions are a linear combination of these two possibilities, i.e. $a_n=c_1(-\lambda)^{n}+c_2$ for some $c_1,c_2\in \mathbb{R}$ determined by the initial conditions. Plugging in the initial conditions, specifically they are determined by the following two linear equations:
\[
\begin{cases}
&a_0=c_1+c_2\\
&a_1=-c_1\lambda+c_2
\end{cases}\implies \begin{cases}
    c_1= \frac{a_0-a_1}{\lambda+1}\\
    c_2=\frac{\lambda a_0+a_1}{\lambda+1}
\end{cases}
.\]
I claim that $(-\lambda)^{n}\to 0$. Let $\epsilon>0$, and choose $N=\log_{\lambda}\left( \epsilon\right) $. Since $0<\lambda<N$ note that $(-\lambda)^{n}$ is a strictly decreasing sequence. Then for $n>N$, we have
\[
\left| (-\lambda)^{n}-0\right|<\left|\lambda\right|^{\log_{\lambda}\left( \epsilon \right) }=\epsilon
.\]
Thus $(-\lambda)^{n}\to 0$. Thus we can conclude that:
\[
\alpha=\lim_{n\to\infty}a_n= \lim_{n\to\infty}\frac{a_0-a_1}{\lambda+1}(-\lambda)^{n}+\frac{\lambda a_0+a_1}{\lambda+1}=\frac{\lambda a_0+a_1}{\lambda+1}
.\]
Since we've found what $\alpha$ is explicitly, clearly we've also found that the sequence converges.

\newpage\phantom{blabla}
\newpage

{\medskip\noindent\bf Question 8a.} Assume that $\inf(S)=0$, and let $R>0$. Since $\inf(S)=0, \exists x\in S$ with $x<\frac{1}{R}\implies \frac{1}{x}>R$. Since $\frac{1}{x}\in S^{-1}$ and $R$ was arbitrary, we have that $\sup(S)=+\infty$.

{\medskip\noindent\bf Question 8b.} Both directions will be proven:

($\Rightarrow$) Let $N=\frac{2}{\inf(S)}$. If there existed $x\in S^{-1}$ with $x>N$ the that would imply that $\frac{1}{x}<\frac{\inf(S)}{2}<\inf(S)$ which would be a contradiction since $\frac{1}{x}\in S$, so $N<\infty$ is an upper bound of $S^{-1}$.

($\Leftarrow$) Let $\epsilon= \frac{1}{2\sup(S^{-1})}$. If there existed $x\in S$ with $x<\epsilon$ then that would imply that $\frac{1}{x}>\frac{1}{\epsilon}=2\sup(S^{-1})>\sup(S^{-1})$, which would be a contradiction since $\frac{1}{x}\in S^{-1}$, so $\epsilon>0$ is a lower bound of $S^{-1}$.

Since both directions hold, the statement is true. When these are true, it remains to be shown that $\sup(S^{-1})=\left( \inf(S) \right) ^{-1}$. Proof by contradiction, assume that $0<\inf(S)<+\infty$ and $\sup(S^{-1})\neq (\inf(S))^{-1}$. Without loss of generality assume that $\sup(S^{-1})>\left( \inf(S) \right) ^{-1}$ (if it's the other way the whole argument just works in reverse as seen just above, I'm getting tired of rewriting things). Then let $x\in ( (\inf(S))^{-1}, \sup(S^{-1}) ] $ with $x\in S^{-1}$, the existence of such an $x$ is guarantee by the definition of a supremum. Then $\frac{1}{x}<\inf(S)\implies x\notin S$ but by the definition of $S^{-1}$ it should be that $\frac{1}{x}\in S$. This is a contradiction, so equality must hold.

{\medskip\noindent\bf Question 8c.} Let $y_n=\sup(\{x_m^{-1}: m>n\})$. There are three cases: $y_n\to 0, y_n\to L\in \mathbb{R}$ or $y_n\to +\infty\in \mathbb{R}$. Note that by part a and b, $y_n=\left(\inf(\{x_m: m>n\})\right)^{-1}$, which can be used to convert between the $\liminf$ and $\limsup$ as follows. If $y_n\to 0$, then $\limsup\limits_{n\to\infty}(x_n^{-1})=0=\frac{1}{+\infty}=\left( \liminf\limits_{n\to\infty} x_n \right)^{-1}$. If $y_n\to L$, then it is simply $\limsup\limits_{n\to\infty}(x_n^{-1})=L=\frac{1}{1 /L}=\left( \liminf\limits_{n\to\infty} x_n \right)^{-1}$. Finally if $y_n\to +\infty$, we get $\limsup\limits_{n\to\infty}(x_n^{-1})=+\infty=\frac{1}{0^{+}}=\left( \liminf\limits_{n\to\infty} x_n \right)^{-1}$.

\newpage\phantom{blabla}
\newpage

\end{document}
